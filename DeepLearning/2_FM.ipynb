{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPPQv1qBbcdmlUVLnRx2b82",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayarnim/M0-RecommenderSystem/blob/main/DeepLearning/2_FM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "8flDVhk42w8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# desc.\n",
        "\n",
        "## sgd\n",
        "\n",
        "- 손실 함수\n",
        "\n",
        "$$\n",
        "L= MSE + \\lambda_{w}\\sum_{i=1}^{n}{w_{i}^{2}} + \\lambda_{v}\\sum_{i=1}^{n}\\sum_{j=1}^{k}{v_{i,j}^{2}}\n",
        "$$\n",
        "\n",
        "- 확률적 경사하강법\n",
        "\n",
        "$$\n",
        "\\theta = \\theta - \\eta \\frac{\\partial L}{\\partial \\theta}\n",
        "$$\n",
        "\n",
        "- 편향 $\\beta$ 갱신 방향\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\beta}\n",
        "= 2(\\hat{y}-y)\n",
        "$$\n",
        "\n",
        "- $i$ 번째 특성에 대한 가중치 $w_{i}$ 갱신 방향\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial w_{i}}\n",
        "= 2(\\hat{y}-y)x_{i}+2\\lambda_{w}w_{i}\n",
        "$$\n",
        "\n",
        "- $i$ 번째 특성에 대한 잠재요인 벡터 $\\overrightarrow{v}_{i}$ 의 $j$ 번째 요소 갱신 방향\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial v_{i,j}}\n",
        "= 2(\\hat{y}-y)(\\sum_{i=1}^{n}v_{i,j}x_{k}x_{i}-v_{k,j}x_{k}^2)+2\\lambda_{v}v_{i,j}\n",
        "$$\n",
        "\n",
        "## predict\n",
        "\n",
        "- `linear_terms`\n",
        "$$\n",
        "\\beta + \\sum_{i=1}^{n}{w_{i}x_{i}}\n",
        "$$\n",
        "\n",
        "- `interactions`\n",
        "\n",
        "$$\n",
        "\\frac{1}{2}\\sum_{i}\\sum_{j\\ne i}{\\overrightarrow{v}_{i}^{T}\\overrightarrow{v}_{j}x_{i}x_{j}}\n",
        "$$\n",
        "\n",
        "## compute_rmse\n",
        "\n",
        "$$\\begin{aligned}\n",
        "\\text{error} \\in \\text{errors}\n",
        "&= (y - \\hat{y})^2\\\\\n",
        "&= \\Big[y - \\big\\{\\beta + \\sum_{i=1}^{n}{w_{i}x_{i}} + \\frac{1}{2}\\sum_{i}\\sum_{j\\ne i}{\\overrightarrow{v}_{i}^{T}\\overrightarrow{v}_{j}x_{i}x_{j}}\\big\\}\\Big]^2\n",
        "\\end{aligned}$$"
      ],
      "metadata": {
        "id": "zwckh2IZ30dK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FM():\n",
        "    def __init__(self, n_factors, learning_rate, reg_w, reg_v, n_iterations):\n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        n_factors       : 잠재요인 수\n",
        "        learning_rate   : 학습률\n",
        "        reg_w           : 가중치 행렬 정규화 강도\n",
        "        reg_v           : 잠재요인 행렬 정규화 강도\n",
        "        n_iterations    : 훈련 횟수\n",
        "        \"\"\"\n",
        "        self.n_factors = n_factors\n",
        "        self.learning_rate = learning_rate\n",
        "        self.reg_w = reg_w\n",
        "        self.reg_v = reg_v\n",
        "        self.n_iterations = n_iterations\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # 편향, 가중치, 잠재요인 초기화\n",
        "        self.b = 0\n",
        "        self.W = np.zeros(n_features)\n",
        "        self.V = np.random.normal(scale=1./self.n_factors, size=(n_features, self.n_factors))\n",
        "\n",
        "        training_process = []\n",
        "\n",
        "        for iteration in range(self.n_iterations):\n",
        "            np.random.shuffle(X)\n",
        "            self.sgd(X, y)\n",
        "            rmse = self.compute_rmse(X, y)\n",
        "            training_process.append((i, rmse))\n",
        "            print(f\"Iteration: {iteration+1}, RMSE: {rmse}\")\n",
        "\n",
        "        return training_process\n",
        "\n",
        "\n",
        "    def sgd(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        for i in range(n_sample):\n",
        "            # 예측 오차 계산\n",
        "            error = self.predict(X[i]) - y[i]\n",
        "\n",
        "            # 편향 갱신\n",
        "            self.b -= self.learning_rate * error\n",
        "            # 가중치 갱신\n",
        "            self.W -= self.learning_rate * (error * X[i] + 2 * self.reg_w * self.W)\n",
        "            # 잠재요인 갱신\n",
        "            for factor in range(self.n_factors):\n",
        "                v_grad = error * (self.X[i] * self.V[:, f] - np.dot(self.X[i], self.X[i] * self.V[:, factor]))\n",
        "                self.V[:, factor] -= self.learning_rate * (v_grad + 2 * self.reg_v * self.V[:, factor])\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_terms = self.b + np.dot(X, self.W)\n",
        "        interactions = 0.5 * np.sum(np.power(np.dot(X, self.V), 2) - np.dot(np.power(X, 2), np.power(self.V, 2)))\n",
        "\n",
        "        return linear_terms + interactions\n",
        "\n",
        "\n",
        "    def compute_rmse(self, X, y):\n",
        "        errors = []\n",
        "        for i in range(X.shape[0]):\n",
        "            pred = self.predict(X[i])\n",
        "            errors.append((pred - y[i]) ** 2)\n",
        "\n",
        "        return np.sqrt(np.mean(errors))"
      ],
      "metadata": {
        "id": "QG2LG8_S0mbP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}